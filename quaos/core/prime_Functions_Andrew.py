import numpy as np
import scipy
import scipy.sparse
import scipy.sparse.linalg
import itertools
import random
import math
import networkx as nx
from functools import reduce
from operator import mul
from .pauli import (pauli, string_to_pauli, pauli_to_matrix)

# NAMING CONVENTIONS

# a - int
# aa - list{int}
# aaa - list{list{int}}
# b - bool
# c - float (constant)
# r - random
# i - indexing
# ss - str
# m - matrix (numpy.array or scipy.sparse.csr_matrix)
# P - Pauli
# C - circuit
# G - gate
# A - graph (adjacency matrix)
# p - number of paulis
# q - number of qudits
# d - dimensions
# functions or methods which end with underscores modify the inputs


def I_mat(d):
    """Return the d-dimensional Identity matrix."""
    return scipy.sparse.csr_matrix(np.diag([1] * d))


def H_mat(d):
    """Return the d-dimensional Hadarmard matrix."""
    omega = math.e**(2 * math.pi * 1j / d)
    H_mat = np.array([[omega**(i0 * i1) for i0 in range(d)] for i1 in range(d)])
    H_mat = 1 / np.sqrt(d) * H_mat 
    return scipy.sparse.csr_matrix(H_mat)


def S_mat(d):
    """Return the d-dimensional S Clifford matrix."""
    if d == 2:
        return scipy.sparse.csr_matrix(np.diag([1, 1j]))

    omega = math.e**(2 * math.pi * 1j / d)
    S_mat = np.diag([omega ** (i * (i - 1) / 2) for i in range(d)])
    return scipy.sparse.csr_matrix(S_mat)


# READING, WRITING, AND MISCELLANEOUS
def read_Luca_Test(path, dims=2):
    """Reads a Hamiltonian file and parses the Pauli strings and coefficients.

    Args:
        path (str): Path to the Hamiltonian file.

    Returns:
        tuple: Number of Paulis in Hamiltonian, number of qudits in Hamiltonian,
            set of Paulis in Hamiltonian, and coefficients in Hamiltonian.
    """
    f = open(path, "r")
    sss0 = f.readlines()
    f.close()
    sss1 = []
    cc = []
    for i0 in range(len(sss0)):
        pauli_list = sss0[i0].split(', {')
        coefficient = pauli_list[0][1:].replace(" ", "").replace('*I', 'j')
        # print(coefficient)
        # print(coefficient[0])
        cc.append(np.complex(coefficient))
        ss = ''
        for i1 in range(1, len(pauli_list)):
            ss += 'x' + str(pauli_list[i1].count('X'))
            ss += 'z' + str(pauli_list[i1].count('Z'))
            ss += ' '
        sss1.append(ss[:-1])
    # if type(dims) == int:
    #     dims = np.array([dims]*(len(sss0[0].split(', {'))-1))
    # elif type(dims) == list:
    #     dims = np.array(dims)

    # cc1 = []
    # for i0 in range(len(sss1)):
    #     pauli_list = sss1[i0].split(' ')
    #     pauli_list_conj = ''
    #     for i1 in range(len(dims)):
    #         ss = pauli_list[i1]
    #         ss_conj = 'x'+str((-int(ss[1]))%int(dims[i1]))+'z'+str((-int(ss[3]))%int(dims[i1]))+' '
    #         pauli_list_conj += ss_conj
    #     cc1.append(1/2*cc[i0]+1/2*np.conj(cc[sss1.index(pauli_list_conj[:-1])]))

    # # cc1 = cc.copy()

    return string_to_pauli(sss1, dims), cc


def loading_bar(runs, length=50, scalings=[]):
    """
    Call within a loop to produce a loading bar which can be scaled for various timings.

    Args:
        runs (list[tuple[int, int]]): List of pairs: current iteration, total iterations.
        length (int): Length of bar.
        scaling (list[function]): Scale speed of progress.
    """
    a0 = len(runs)
    scalings += [lambda x:x] * (a0 - len(scalings))
    a1 = scalings[0](runs[0][0]) + sum(scalings[i](runs[i][0]) * scalings[i - 1](runs[i - 1][1]) for i in range(1, a0))
    a2 = reduce(mul, [scalings[i](runs[i][1]) for i in range(a0)])
    # for scale in scalings[::-1]:
    #     a1,a2 = scale(a1),scale(a2)
    ss0 = ("{0:.1f}").format(int(1000 * a1 / a2) / 10)
    ss1 = ' '.join(str(runs[i][0]) + '/' + str(runs[i][1]) for i in range(a0))
    bar = 'â–ˆ' * int(length * a1 / a2) + '-' * (length - int(length * a1 / a2))
    print(f' |{bar}| {ss0}% {ss1}', end="\r")
    if runs[0][0] >= runs[0][1] - 1: 
        print(" " * (length + 6 + len(ss0) + len(ss1)), end="\r")


# GATES & CIRCUITS
class gate:
    """A class for storing quantum gates as a name and a list of qudits.

    Attributes:
        name (function): Function representing the action of the gate.
        aa (list[int]): List of qudits acted upon.
    """
    def __init__(self, name, aa):
        """
        Args:
            name (function): Function representing the action of the gate.
            aa (list[int]): List of qudits acted upon.
        """
        self.name = name
        self.aa = aa

    def name_string(self):
        """Returns the name of the gate as a string.

        Returns:
            str: Name of function as a string.
        """
        return self.name.__name__

    def copy(self):
        """
        Deep copy of self.

        Returns:
            gate: A deep copy of gate.
        """
        return gate(self.name, [a for a in self.aa])

    def print(self):
        """Print self as a name and a tuple of qudits.

        Prints the name of the gate and a tuple of the qudits it acts on.
        """
        print("%s(%s)" % (self.name_string(), str(self.aa).replace(' ', '')[1:-1]))


class circuit:
    """
    A class for storing quantum circuits as a collection of gates along with the dimension.

    Attributes:
        dims (list[int]): Dimensions of the qudits in the circuit.
        gg (list[gate]): List of gates in the circuit.

    Methods:
        length(): Returns the number of gates in the circuit.
        unitary(): Converts the circuit to its corresponding unitary matrix.
        add_gates_(C): Appends gates to the end of the circuit.
    """
    def __init__(self, dims):
        """A class for storing quantum circuits as a collection of gates along with the dimension.

        Args:
            qudits (int): Number of qudits in circuit.
        """
        self.dims = dims
        self.gg = []

    def length(self):
        """Returns the number of gates in the circuit.

        Returns:
            int: The number of gates in the circuit.
        """
        return len(self.gg)

    def unitary(self):
        """
        Convert self to its corresponding unitary matrix.

        Returns:
            scipy.sparse.csr_matrix: Unitary matrix representation of self.
        """
        q = len(self.dims)
        m = scipy.sparse.csr_matrix(([1] * (np.prod(self.dims)), (range(np.prod(self.dims)), range(np.prod(self.dims)))))
        for g in self.gg:
            m = globals()[g.name_string() + '_unitary'](g.aa, self.dims) @ m
        return m

    def add_gates_(self, C):
        """Append gates to the end of self.

        Args:
            C (circuit or list[gate] or gate): Gates to be appended to self.
        """
        if type(C) is circuit:
            self.gg += C.gg
        elif type(C) is gate:
            self.gg.append(C)
        else:
            self.gg += C

    def insert_gates_(self, C, a):
        """
        Insert gates at a given timestep in self.

        Args:
            C (circuit or list[gate] or gate): Gates to be inserted into self.
            a (int): Index for insertion.
        """
        if type(C) is gate:
            self.gg.insert(a, C)
        elif type(C) is circuit:
            self.gg[a:a] = C.gg
        else:
            self.gg[a:a] = C

    def delete_gates_(self, aa):
        """
        Delete gates at specific timesteps.

        Parameters:
            aa (int or list[int]): Indices where gates should be deleted.
        """
        if type(aa) is int:
            del self.gg[aa]
        else:
            self.gg = [self.gg[i] for i in range(length(self.dims)) if not i in aa]

    def copy(self):
        """Deep copy of self.

        Returns:
            circuit: A deep copy of self.
        """
        return circuit(self.dims, [g.copy() for g in self.gg])

    def print(self):
        """Print self as gates on consecutive lines."""
        for g in self.gg:
            g.print()


def act(P, C):
    """Returns the outcome of a given circuit (or gate or list of gates) acting on a given pauli.

    Parameters:
        P (pauli): Pauli to be acted upon
        C (gate or circuit or list[gate]): gates to act on Pauli

    Returns:
        pauli: result of C acting on P by conjugation
    """
    if P == None:
        return P
    elif type(C) is gate:
        return C.name(P, C.aa)
    elif type(C) is circuit:
        return act(P, C.gg)
    elif len(C) == 0:
        return P
    elif len(C) == 1:
        return act(P, C[0])
    else:
        return act(act(P, C[0]), C[1:])


def H(P, aa):
    """
    Function for the gate representation of Hadamard gate. Transformation: 
    X -> Z, Z -> -X

    Args:
        P (pauli): Pauli to be acted upon.
        aa (list[int]): Qudits to be acted upon.

    Returns:
        pauli: Result of H(aa) acting on P.
    """
    Q = P.copy()
    X, Z = Q.X, Q.Z
    for a in aa:
        for i in range(Q.paulis()):
            Q.phases[i] += X[i, a] * Z[i, a] * P.lcm // P.dims[a]
        X[:, a], Z[:, a] = -Z[:, a].copy(), X[:, a].copy()
    return pauli(X, Z, Q.dims, Q.phases)


def S(P, aa):
    """
    Function for the gate representation of phase gate. Phase gate transformation: 
    X -> XZ,Z -> Z

    Parameters:
        P (pauli): Pauli to be acted upon.
        aa (list[int]): Qudits to be acted upon.

    Returns:
        pauli: Result of S(aa) acting on P.
    """
    Q = P.copy()
    X, Z = Q.X, Q.Z
    for a in aa:
        for i in range(Q.paulis()):
            if P.dims[a] == 2:
                Q.phases[i] += X[i, a] * Z[i, a] * P.lcm // P.dims[a]
            else:
                Q.phases[i] += math.comb(X[i, a], 2) * P.lcm // P.dims[a]
        Z[:, a] += X[:, a]
    return pauli(X, Z, Q.dims, Q.phases)


def CX(P, aa):
    """
    Function for the gate representation of CNOT gate. Transformation:
        X*I -> X*X
        I*X -> I*X
        Z*I -> Z*I
        I*Z -> -Z*Z

    Parameters:
        P (pauli): Pauli to be acted upon.
        aa (list[int]): Control aa[0] and target aa[1].

    Returns:
        pauli: Result of CNOT(aa[0],aa[1]) acting on P.
    """
    a0, a1 = aa[0], aa[1]
    if P.dims[a0] != P.dims[a1]:
        raise Exception("Entangling gates must be between two qudits of equal dimensions")
    Q = P.copy()
    X, Z = Q.X, Q.Z
    for i in range(Q.paulis()):
        if P.dims[a0] == 2:
            Q.phases[i] += X[i, a0] * Z[i, a1] * (X[i, a1] + Z[i, a0] + 1) * P.lcm // P.dims[a0]
    X[:, a1] += X[:, a0]
    Z[:, a0] -= Z[:, a1]
    return pauli(X, Z, Q.dims, Q.phases)


def SWAP(P, aa):
    """Function for the gate representation of SWAP gate. Gate transformation: 
    X*I -> I*X, I*X -> X*I, Z*I -> I*Z, I*Z -> Z*I

    Parameters:
        P (pauli): Pauli to be acted upon.
        aa (list[int]): Targets aa[0] and aa[1].

    Returns:
        pauli: result of SWAP(aa[0],aa[1]) acting on P.

    """
    X, Z = P.X, P.Z
    a0, a1 = aa[0], aa[1]
    X[:, a0], X[:, a1] = X[:, a1].copy(), X[:, a0].copy()
    Z[:, a0], Z[:, a1] = Z[:, a1].copy(), Z[:, a0].copy()
    return pauli(X, Z)


def H_unitary(aa,dims):
    """Function for mapping Hadamard gate to corresponding unitary matrix

    Parameters:
        aa (list{int}): indices for Hadamard tensors
        dims (list{int}): dimensions of the qudits

    Returns:
        scipy.sparse.csr_matrix: matrix representation of q-dimensional H(aa)
    """
    return tensor([H_mat(dims[i]) if i in aa else I_mat(dims[i]) for i in range(len(dims))])


def S_unitary(aa,dims):
    """
    Function for mapping phase gate to corresponding unitary matrix.

    Parameters:
        aa (list[int]): indices for phase gate tensors
        dims (list[int]): dimensions of the qudits

    Returns:
        scipy.sparse.csr_matrix: matrix representation of q-dimensional S(aa)
    """
    return tensor([S_mat(dims[i]) if i in aa else I_mat(dims[i]) for i in range(len(dims))])


def bases_to_int(aa, dims):
    dims = np.flip(dims)
    aa = np.flip(aa)
    a = aa[0] + sum([aa[i1] * np.prod(dims[:i1]) for i1 in range(1, len(dims))])
    dims = np.flip(dims)
    aa = np.flip(aa)
    return a


def int_to_bases(a, dims):
    dims = np.flip(dims)
    aa = [a % dims[0]]
    for i in range(1, len(dims)):
        s0 = aa[0] + sum([aa[i1] * dims[i1 - 1] for i1 in range(1, i)])
        s1 = np.prod(dims[:i])
        aa.append(((a - s0) // s1) % dims[i])
    dims = np.flip(dims)
    return np.flip(np.array(aa))


def CX_func(i, a0, a1, dims):
    aa = int_to_bases(i, dims)
    aa[a1] = (aa[a1] + aa[a0]) % dims[a1]
    return bases_to_int(aa, dims)


def CX_unitary(aa, dims):
    """
    Function for mapping CNOT gate to corresponding unitary matrix.

    Parameters:
        aa (list[int]): Control aa[0] and target aa[1].
        dims (list[int]): Dimensions of the qudits.

    Returns:
        scipy.sparse.csr_matrix: Matrix representation of q-dimensional CNOT(aa[0], aa[1]).
    """
    q = len(dims)
    D = np.prod(dims)
    a0 = aa[0]
    a1 = aa[1]
    aa2 = np.array([1 for i in range(D)])
    aa3 = np.array([CX_func(i, a0, a1, dims) for i in range(D)])
    aa4 = np.array([i for i in range(D)])
    return scipy.sparse.csr_matrix((aa2, (aa3, aa4)))


def SWAP_func(i, a0, a1, dims):
    aa = int_to_bases(i, dims)
    aa[a0], aa[a1] = aa[a1], aa[a0]
    return sum([aa[i] * int(np.prod(dims[:i])) for i in range(len(aa))])


def SWAP_unitary(aa, dims):
    """
    Function for mapping SWAP gate to corresponding unitary matrix.

    Parameters:
        aa (list[int]): Targets aa[0] and aa[1].
        dims (list[int]): Dimensions of the qudits.

    Returns:
        scipy.sparse.csr_matrix: Matrix representation of q-dimensional SWAP(aa[0],aa[1]).
    """
    D = np.prod(dims)
    a0 = q - 1 - aa[0]
    a1 = q - 1 - aa[1]
    aa2 = np.array([1 for i in range(D)])
    aa3 = np.array([i for i in range(D)])
    aa4 = np.array([SWAP_func(i, a0, a1, dims) for i in range(D)])
    return scipy.sparse.csr_matrix((aa2, (aa3, aa4)))

# returns the circuit which diagonalizes a pairwise commuting pauli object
def diagonalize(P):
    # Inputs:
    #     P - (pauli) - Pauli to be diagonalized
    # Outputs:
    #     (circuit) - circuit which diagonalizes P
    dims = P.dims
    q = P.qudits()

    if not P.is_commuting():
        raise Exception("Paulis must be pairwise commuting to be diagonalized")
    P1 = P.copy()
    C = circuit(dims)

    if P.is_quditwise_commuting():
        # for each dimension, call diagonalize_iter_quditwise_ on the qudits of the same dimension
        for d in sorted(set(dims)):
            aa = [i for i in range(q) if dims[i]==d]
            while aa:
                C = diagonalize_iter_quditwise_(P1,C,aa)
        P1 = act(P1,C)
    else:
        # for each dimension, call diagonalize_iter_ on the qudits of same dimension
        for d in sorted(set(dims)):
            aa = [i for i in range(q) if dims[i]==d]
            while aa:
                C = diagonalize_iter_(P1,C,aa)
        P1 = act(P1,C)

    # if any qudits are X rather than Z, apply H to make them Z
    if [i for i in range(q) if any(P1.X[:,i])]:
        g = gate(H,[i for i in range(q) if any(P1.X[:,i])])
        C.add_gates_(g)
        P1 = act(P1,g)
    return C

# an iterative function called within diagonalize()
def diagonalize_iter_(P,C,aa):
    # Inputs:
    #     P  - (pauli)     - Pauli to be diagonalized
    #     C  - (circuit)   - circuit which diagonalizes first a-1 qudits
    #     aa - (list{int}) - remaining qudits of same dimension
    # Outputs:
    #     (circuit) - circuit which diagonalizes first a qudits
    p,q = P.paulis(),P.qudits()
    P = act(P,C)
    a = aa.pop(0)

    # if all Paulis have no X-part on qudit a, return C
    if not any(P.X[:,a]):
        return C

    # set a1 to be the index of the minimum Pauli with non-zero X-part of qudit a
    a1 = min(i for i in range(p) if P.X[i,a])

    # add CNOT gates to cancel out all non-zero X-parts on Pauli a1, qudits in aa
    while any(P.X[a1,i] for i in aa):
        gg = [gate(CX,[a,i]) for i in aa if P.X[a1,i]]
        C.add_gates_(gg)
        P = act(P,gg)

    # check whether there are any non-zero Z-parts on Pauli a1, qudits in aa
    while any(P.Z[a1,i] for i in aa):

        # if Pauli a1, qudit a is X, apply S gate to make it Y
        if not P.Z[a1,a]:
            g = gate(S,[a])
            C.add_gates_(g)
            P = act(P,g)

        # add backwards CNOT gates to cancel out all non-zero Z-parts on Pauli a1, qudits in aa
        gg = [gate(CX,[i,a]) for i in aa if P.Z[a1,i]]
        C.add_gates_(gg)
        P = act(P,gg)

    # if Pauli a1, qudit a is Y, add S gate to make it X
    while P.Z[a1,a]:
        g = gate(S,[a])
        C.add_gates_(g)
        P = act(P,g)
    return C

# an iterative function called within diagonalize()
def diagonalize_iter_quditwise_(P,C,aa):
    # Inputs:
    #     P  - (pauli)     - Pauli to be diagonalized
    #     C  - (circuit)   - circuit which diagonalizes first a-1 qudits
    #     aa - (list{int}) - remaining qudits of same dimension
    # Outputs:
    #     (circuit) - circuit which diagonalizes first a qudits
    p,q = P.paulis(),P.qudits()
    P = act(P,C)
    a = aa.pop(0)

    # if all Paulis have no X-part on qudit a, return C
    if not any(P.X[:,a]):
        return C

    # set a1 to be the index of the minimum Pauli with non-zero X-part of qudit a
    a1 = min(i for i in range(p) if P.X[i,a])

    # if Pauli a1, qudit a is Y, add S gate to make it X
    while P.Z[a1,a]:
        g = gate(S,[a])
        C.add_gates_(g)
        P = act(P,g)
    return C

# checks whether circuit properly diagonalizes subset of Paulis
def is_diagonalizing_circuit(P,C,aa):
    P1 = P.copy()
    P1.delete_paulis_([i for i in range(P.paulis()) if not i in aa])
    P1 = act(P1,C)
    return P1.is_IZ()



# GRAPHS

# a class for storing graphs as adjacency matrices
#     since we are dealing with covariance matrices with both vertex and edge weights,
#     this is a suitable format to capture that complexity
class graph:
    # Inputs:
    #     adj_mat - (numpy.array) - (weighted) adjacency matrix of graph
    #     dtype   - (numpy.dtype) - data type of graph weights
    def __init__(self,adj_mat=np.array([]),dtype=complex):
        self.adj = adj_mat.astype(dtype)

    # adds a vertex to self
    def add_vertex_(self,c=1):
        # Inputs:
        #     c - (float) - vertex weight
        if len(self.adj) == 0:
            self.adj = np.array([c])
        else:
            m0 = np.zeros((len(self.adj),1))
            m1 = np.zeros((1,len(self.adj)))
            m2 = np.array([[c]])
            self.adj = np.block([[self.adj,m0],[m1,m2]])

    # weight a vertex
    def lade_vertex_(self,a,c):
        # Inputs:
        #     a - (int)   - vertex to be weighted
        #     c - (float) - vertex weight
        self.adj[a,a] = c

    # weight an edge
    def lade_edge_(self,a0,a1,c):
        # Inputs:
        #     a0 - (int)   - first vertex
        #     a1 - (int)   - second vertex
        #     c  - (float) - vertex weight
        self.adj[a0,a1] = c
        self.adj[a1,a0] = c

    # returns a set of the neighbors of a given vertex
    def neighbors(self,a):
        # Inputs:
        #     a - (int) - vertex for which neighbors should be returned
        # Outputs:
        #     (list{int}) - set of neighbors of vertex a
        aa1 = set([])
        for i in range(self.ord()):
            if (a != i) and (self.adj[a,i] != 0):
                aa1.add(i)
        return aa1

    # returns list of all edges in self
    def edges(self):
        # Outputs:
        #     (list{list{int}}) - list of edges in self
        aaa = []
        for i0,i1 in itertools.combinations(range(self.ord()),2):
            if i1 in self.neighbors(i0):
                aaa.append([i0,i1])
        return aaa

    # check whether a collection of vertices is a clique in self
    def clique(self,aa):
        # Inputs:
        #     aa - (list{int}) - list of vertices to be checked for clique
        # Outputs:
        #     (bool) - True if aa is a clique in self; False otherwise
        for i0,i1 in itertools.combinations(aa,2):
            if self.adj[i0,i1] == 0:
                return False
        return True

    # returns the degree of a given vertex
    def degree(self,a):
        # Inputs:
        #     a - (int) - vertex for which degree should be returned
        # Outputs:
        #     (int) - degree of vertex a
        return np.count_nonzero(self.adj[a,:])

    # returns the number of vertices in self
    def ord(self):
        # Outputs:
        #     (int) - number of vertices in self
        return self.adj.shape[0]

    # print adjacency matrix representation of self
    def print(self):
        for i0 in range(self.ord()):
            print('[',end=' ')
            for i1 in range(self.ord()):
                s = self.adj[i0,i1]
                if str(s)[0] == '-':
                    print(f'{self.adj[i0,i1]:.2f}',end=" ")
                else:
                    print(' '+f'{self.adj[i0,i1]:.2f}',end=" ")
            print(']')

    # print self as a list of vertices together with their neighbors
    def print_neighbors(self):
        for i0 in range(self.ord()):
            print(i0,end=": ")
            for i1 in self.neighbors(i0):
                print(i1,end=" ")
            print()

    # return a deep copy of self
    def copy(self):
        # Outputs:
        #     (graph) - deep copy of self
        return graph(np.array([[self.adj[i0,i1] for i1 in range(self.ord())] for i0 in range(self.ord)]))

# returns all non-empty cliques in a graph
def nonempty_cliques(A):
    # Inputs:
    #     A - (graph) - graph for which all cliques should be found
    # Outputs:
    #     (list{list{int}}) - a list containing all non-empty cliques in A
    p = A.ord()
    aaa = set([frozenset([])])
    for i in range(p):
        iset = set([i])
        inter = A.neighbors(i)
        aaa |= set([frozenset(iset|(inter&aa)) for aa in aaa])
    aaa.remove(frozenset([]))
    return list([list(aa) for aa in aaa])

# returns an generator over all maximal cliques in a graph
def all_maximal_cliques(A):
    # Inputs:
    #     A - (graph) - graph for which all cliques should be found
    # Outputs:
    #     (generator) - a generator over all maximal cliques in A
    p = A.ord()
    N = {}
    for i in range(p):
        N[i] = A.neighbors(i)
    nxG = nx.Graph()
    nxG.add_nodes_from([i for i in range(p)])
    nxG.add_edges_from([(i0,i1) for i0 in range(p) for i1 in N[i0]])
    return nx.algorithms.clique.find_cliques(nxG)

# returns a clique covering of a graph which hits every vertex at least a certain number of times
def weighted_vertex_covering_maximal_cliques(A,A1=None,cc=None,k=1):
    # Inputs:
    #     A  - (graph)     - commutation graph for which covering should be found
    #     A1 - (graph)     - variance graph for which covering should be found
    #     cc - (list{int}) - coefficients of the Hamiltonian
    #     k  - (int)       - number of times each vertex should be covered
    # Outputs:
    #     (list{list{int}}) - a list containing cliques which cover A
    p = A.ord()
    if A1 == None and cc == None:
        return vertex_covering_maximal_cliques(A,k=k)
    elif A1 == None:
        cc2 = [np.abs(cc[i])**2 for i in range(p)]
        N = {}
        for i in range(p):
            N[i] = A.neighbors(i)
        aaa = []
        for i0 in range(p):
            for i1 in range(k):
                aa0 = [i0]
                aa1 = list(N[i0])
                while aa1:
                    c1 = sum(cc2[a0] for a0 in aa0)
                    cc1 = [c1+sum(cc2[a2] for a2 in N[a1].intersection(aa1)) for a1 in aa1]
                    if sum(cc1) == 0:
                        cc1 = [1 for a in aa1]
                    r = random.choices(aa1,cc1)[0]
                    aa0.append(r)
                    aa1 = list(N[r].intersection(aa1))
                aaa.append(aa0)
        return [sorted(list(aa1)) for aa1 in set([frozenset(aa) for aa in aaa])]
    else:
        V1 = A1.adj
        N = {}
        for i in range(p):
            N[i] = A.neighbors(i)
        N2 = {}
        for i in range(p):
            N2[i] = A.neighbors(i)|set([i])
        aaa = []
        for i0 in range(p):
            for i1 in range(k):
                aa0 = [i0]
                aa1 = list(N[i0])
                aa2 = aa0+aa1
                while aa1:
                    cc1 = [V1[list(N2[a1].intersection(aa2))][:,list(N2[a1].intersection(aa2))].sum() for a1 in aa1]
                    if sum(cc1) == 0:
                        cc1 = [1 for a in aa1]
                    r = random.choices(aa1,cc1)[0]
                    aa0.append(r)
                    aa1 = list(N[r].intersection(aa1))
                    aa2 = aa0+aa1
                aaa.append(aa0)
        return [sorted(list(aa1)) for aa1 in set([frozenset(aa) for aa in aaa])]

# returns a clique covering of a graph which hits every vertex at least a certain number of times
def vertex_covering_maximal_cliques(A,k=1):
    # Inputs:
    #     A - (graph) - commutation graph for which covering should be found
    #     k - (int)   - number of times each vertex must be covered
    # Outputs:
    #     (list{list{int}}) - a list containing cliques which cover A
    p = A.ord()
    N = {}
    for i in range(p):
        N[i] = A.neighbors(i)
    aaa = []
    for i0 in range(p):
        for i1 in range(k):
            aa0 = [i0]
            aa1 = list(N[i0])
            while aa1:
                cc = [len(N[a1].intersection(aa1)) for a1 in aa1]
                if sum(cc) == 0:
                    cc = [1 for a in aa1]
                r = random.choices(aa1,cc)[0]
                aa0.append(r)
                aa1 = list(N[r].intersection(aa1))
            aaa.append(aa0)
    return [sorted(list(aa1)) for aa1 in set([frozenset(aa) for aa in aaa])]

# reduces a clique covering of a graph by removing cliques with lowest weight
def post_process_cliques(A,aaa,k=1):
    # Inputs:
    #     A   - (graph)           - varaince graph from which weights of cliques can be obtained
    #     aaa - (list{list{int}}) - a clique covering of the Hamiltonian
    #     k   - (int)             - number of times each vertex must be covered
    # Outputs:
    #     (list{list{int}}) - a list containing cliques which cover A
    p = A.ord()
    V = A.adj
    s = np.array([sum([i in aa for aa in aaa]) for i in range(p)])
    D = {}
    for aa in aaa:
        D[str(aa)] = V[aa][:,aa].sum()
    aaa1 = aaa.copy()
    aaa1 = list(filter(lambda x : all(a>=(k+1) for a in s[aa]),aaa1))
    while aaa1:
        aa = min(aaa1,key=lambda x : D[str(x)])
        aaa.remove(aa)
        aaa1.remove(aa)
        s -= np.array([int(i in aa) for i in range(p)])
        aaa1 = list(filter(lambda x : all(a>=(k+1) for a in s[aa]),aaa1))
    return aaa

# returns a largest-degree-first clique partition of a graph
def LDF(A):
    # Inputs:
    #     A - (graph) - graph for which partition should be found
    # Outputs:
    #     (list{list{int}}) - a list containing cliques which partition A
    p = A.ord()
    remaining = set(range(p))
    N = {}
    for i in range(p):
        N[i] = A.neighbors(i)
    aaa = []
    while remaining:
        a = max(remaining,key=lambda x : len(N[x]&remaining))
        aa0 = set([a])
        aa1 = N[a]&remaining
        while aa1:
            a2 = max(aa1,key=lambda x : len(N[x]&aa1))
            aa0.add(a2)
            aa1 &= N[a2]
        aaa.append(aa0)
        remaining -= aa0
    return [sorted(list(aa)) for aa in aaa]



# PHYSICS FUNCTIONS

# returns the tensor product of a list of matrices
def tensor(mm):
    # Inputs:
    #     mm - (list{scipy.sparse.csr_matrix}) - matrices to tensor
    # Outputs:
    #     (scipy.sparse.csr_matrix) - tensor product of matrices
    if len(mm) == 0:
        return matrix([])
    elif len(mm) == 1:
        return mm[0]
    else:
        return scipy.sparse.kron(mm[0],tensor(mm[1:]),format="csr")

# returns the mean of a single Pauli with a given state
def Mean(P,psi):
    # Inputs:
    #     P   - (pauli)       - Pauli for mean
    #     psi - (numpy.array) - state for mean
    # Outputs:
    #     (numpy.float64) - mean <psi|P|psi>
    m = pauli_to_matrix(P)
    psi_dag = psi.conj().T
    mean = psi_dag @ m @ psi
    return mean

# returns the mean of a Hamiltonian with a given state
def Hamiltonian_Mean(P,cc,psi):
    # Inputs:
    #     P   - (pauli)       - Paulis of Hamiltonian
    #     cc  - (list{float}) - coefficients of Hamiltonian
    #     psi - (numpy.array) - state for mean
    # Outputs:
    #     (numpy.float64) - mean sum(c*<psi|P|psi>)
    p = P.paulis()
    return sum(cc[i]*Mean(P.a_pauli(i),psi) for i in range(p))

# returns the variance of a single Pauli with a given state
def Var(P,psi):
    # Inputs:
    #     P   - (pauli)       - Pauli for variance
    #     psi - (numpy.array) - state for variance
    # Outputs:
    #     (numpy.float64) - variance <psi|P^2|psi> - <psi|P|psi>^2
    # Output: 
    m = pauli_to_matrix(P)
    psi_dag = psi.conj().T
    var = (psi_dag @ m @ m @ psi)-(psi_dag @ m @ psi)**2
    return var.real

# returns the variance of two single Paulis with a given state
def Cov(P0,P1,psi):
    # Inputs:
    #     P0  - (pauli)       - first Pauli for covariance
    #     P1  - (pauli)       - second Pauli for covariance
    #     psi - (numpy.array) - state for covariance
    # Outputs:
    #     (numpy.float64) - covariance <psi|P0P1|psi> - <psi|P0|psi><psi|P1|psi>
    m0 = pauli_to_matrix(P0)
    m1 = pauli_to_matrix(P1)
    psi_dag = psi.conj().T
    cov = (psi_dag @ m0 @ m1 @ psi)-(psi_dag @ m0 @ psi)*(psi_dag @ m1 @ psi)
    return cov.real

# returns the graph of variances and covariances for a given Hamiltonian and ground state
def variance_graph(P,cc,psi):
    # Inputs:
    #     P   - (pauli)         - set of Paulis in Hamiltonian
    #     cc  - (list{float64}) - coefficients in Hamiltonian
    #     psi - (numpy.array)   - ground state
    # Outputs:
    #     (graph) - variances and covariances of all Paulis with respect to ground state
    p = P.paulis()
    mm = [pauli_to_matrix(P.a_pauli(i)) for i in range(p)]
    psi_dag = psi.conj().T
    cc1 = [psi_dag@mm[i]@psi for i in range(p)]
    cc2 = [psi_dag@mm[i].conj().T@psi for i in range(p)]
    return graph(np.array([[np.conj(cc[i0])*cc[i1]*((psi_dag@mm[i0].conj().T@mm[i1]@psi)-cc2[i0]*cc1[i1]) for i1 in range(p)] for i0 in range(p)]))

# scales the entries in a variance graph with respect to number of measurements
def scale_variances(A,S):
    # Inputs:
    #     A - (graph)       - variance matrix
    #     S - (numpy.array) - array for tracking number of measurements
    p = A.ord()
    S1 = S.copy()
    S1[range(p),range(p)] = [a if a != 0 else 1 for a in S1.diagonal()]
    s1 = 1/S1.diagonal()
    return graph(S1*A.adj*s1*s1[:,None])

# returns the commutation graph of a given Pauli
def commutation_graph(P):
    # Inputs:
    #     P - (pauli) - Pauli to check for commutation relations
    # Outputs:
    #     (graph) - an edge is weighted 1 if the pair of Paulis commute
    p = P.paulis()
    return graph(np.array([[1-symplectic_inner_product(P.a_pauli(i0),P.a_pauli(i1)) for i1 in range(p)] for i0 in range(p)]))

# returns the quditwise commutation graph of a given Pauli
def quditwise_commutation_graph(P):
    # Inputs:
    #     P - (pauli) - Pauli to check for quditwise commutation relations
    # Outputs:
    #     (graph) - an edge is weighted 1 if the pair of Paulis quditwise commute
    p = P.paulis()
    return graph(np.array([[1-quditwise_inner_product(P.a_pauli(i0),P.a_pauli(i1)) for i1 in range(p)] for i0 in range(p)]))

# returns a random Hamiltonian with given number of Paulis, number of qudits, and Pauli weight
def random_Ham(p,q,d):
    # Inputs:
    #     p - (int) - number of Paulis
    #     q - (int) - number of qudits
    #     d - (int) - max Pauli weight
    # Outputs:
    #     (pauli) - random set of Paulis satisfying input conditions
    sss = []
    ssdict = {0:"I",1:"Z",2:"X",3:"Y"}
    for i in range(p):
        rr = random.sample(range(q),d)
        sss.append("".join([ssdict[random.randint(0,3)] if i1 in rr else "I" for i1 in range(q)]))
    return string_to_pauli(sss)

# print list of Paulis in string form, together with coefficients
def print_Ham_string(P,cc):
    # Inputs:
    #     P  - (pauli)     - Pauli to be printed
    #     cc - (list{int}) - coefficients for Hamiltonian
    X,Z = P.X,P.Z
    for i in range(P.paulis()):
        print(pauli_to_string(P.a_pauli(i)),end="")
        print('',cc[i])

# returns the ground state of a given Hamiltonian
def ground_state(P,cc):
    # Inputs:
    #     P  - (pauli)     - Paulis for Hamiltonian
    #     cc - (list{int}) - coefficients for Hamiltonian
    # Outputs:
    #     (numpy.array) - eigenvector corresponding to lowest eigenvalue of Hamiltonian
    m = sum(pauli_to_matrix(P.a_pauli(i))*cc[i] for i in range(P.paulis()))
    
    
    m = m.toarray()
    val,vec = np.linalg.eig(m)
    val = np.real(val)
    vec = np.transpose(vec)
    
    tmp_index = val.argmin(axis=0)
    
    #print(val)
    #print(tmp_index)
    #print(val[tmp_index])
    
    
    gs = vec[tmp_index]
    gs = np.transpose(gs)
    gs = gs / np.linalg.norm(gs)
    
    if abs(min(val) - np.transpose(np.conjugate(gs))@m@gs)>10**-10:
        print("ERROR with the GS!!!")
    
    #print(gs)
    #print(np.linalg.norm(gs))
    #print(np.transpose(np.conjugate(gs))@m@gs)
    
    return gs

    
    
    #gval,gvec = scipy.sparse.linalg.eigsh(m,which='SA',k=1)
    #tmp_state = np.array([g for g in gvec[:,0]])
    #return tmp_state/np.linalg.norm(tmp_state)



# MEASUREMENT FUNCTIONS

# sample from distribution given by ground state and eigenstates of clique
#     optionally input a dictionary, which will be updated to track speed up future samples
def sample_(P,psi,aa,D={}):
    # Inputs:
    #     P   - (pauli)       - Paulis for Hamiltonian
    #     psi - (numpy.array) - ground state of Hamiltonian
    #     aa  - (list{int})   - clique to be measured
    #     D   - (dict)        - dictionary for storing pdf and negations for future samples
    # Outputs:
    #     (list{int}) - ith entry is +1/-1 for measurement outcome on ith element of aa
    if str(aa) in D.keys():
        P1,pdf = D[str(aa)]
    else:
        P1 = P.copy()
        P1.delete_paulis_([i for i in range(P.paulis()) if not i in aa])
        C = diagonalize(P1)
        psi_diag = C.unitary() @ psi
        pdf = np.absolute(psi_diag*psi_diag.conj())
        P1 = act(P1,C)
        D[str(aa)] = (P1,pdf)
    p,q,phases,dims = P1.paulis(),P1.qudits(),P1.phases,P1.dims
    a1 = np.random.choice(np.prod(dims),p=pdf)
    bases_a1 = int_to_bases(a1,dims)
    ss = [(phases[i0]+sum((bases_a1[i1]*P1.Z[i0,i1]*P1.lcm)//P1.dims[i1] for i1 in range(q)))%P1.lcm for i0 in range(p)]
    return ss



# ESTIMATED PHYSICS FUNCTIONS

# Bayesian estimation of mean from samples
def bayes_Mean(xDict):
    # Inputs:
    #     xDict - (Dict) - number of ++/+-/-+/-- outcomes for single Pauli
    # Outputs:
    #     (float) - Bayesian estimate of mean
    x0,x1 = xDict[(1,1)],xDict[(-1,-1)]
    return (x0-x1)/(x0+x1+2)

# Bayesian estimation of variance from samples
def bayes_Var(xDict):
    # Inputs:
    #     xDict - (Dict) - number of ++/+-/-+/-- outcomes for single Pauli
    # Outputs:
    #     (float) - Bayesian variance of mean
    lcm = int(np.sqrt(len(xDict)))
    alpha = [math.e**(2*math.pi*1j*i/lcm) for i in range(lcm)]
    alpha_conj = [math.e**(-2*math.pi*1j*i/lcm) for i in range(lcm)]
    s = sum(xDict[(i,i)] for i in range(lcm))
    return sum(alpha[i]*(alpha_conj[i]-alpha_conj[j])*(xDict[(i,i)]+1)*(xDict[(j,j)]+1)/((s+lcm)*(s+lcm+1)) for i,j in itertools.product(range(lcm),repeat=2))

# Bayesian estimation of covariance from samples
def bayes_Cov(xyDict,xDict,yDict):
    # Inputs:
    #     xyDict - (Dict) - number of ++/+-/-+/-- outcomes for pair of Paulis
    #     xDict  - (Dict) - number of ++/+-/-+/-- outcomes for first Pauli
    #     xDict  - (Dict) - number of ++/+-/-+/-- outcomes for second Pauli
    # Outputs:
    #     (float) - Bayesian estimate of mean
    lcm = int(np.sqrt(len(xyDict)))
    alpha = [math.e**(2*math.pi*1j*i/lcm) for i in range(lcm)]
    alpha_conj = [math.e**(-2*math.pi*1j*i/lcm) for i in range(lcm)]
    s = sum(xyDict[(i,j)] for i,j in itertools.product(range(lcm),repeat=2))
    return sum((alpha_conj[i0]-alpha_conj[j0])*(alpha[i1]-alpha[j1])*(xyDict[(i0,i1)]+1)*(xyDict[(j0,j1)]+1)/(2*(s+lcm)*(s+lcm+1)) for (i0,i1),(j0,j1) in itertools.product(itertools.product(range(lcm),repeat=2),repeat=2))
    # xy00,xy01,xy10,xy11 = xyDict[(1,1)],xyDict[(1,-1)],xyDict[(-1,1)],xyDict[(-1,-1)]
    # x0,x1 = xDict[(1,1)],xDict[(-1,-1)]
    # y0,y1 = yDict[(1,1)],yDict[(-1,-1)]
    # p00 = 4*((x0+1)*(y0+1))/((x0+x1+2)*(y0+y1+2))
    # p01 = 4*((x0+1)*(y1+1))/((x0+x1+2)*(y0+y1+2))
    # p10 = 4*((x1+1)*(y0+1))/((x0+x1+2)*(y0+y1+2))
    # p11 = 4*((x1+1)*(y1+1))/((x0+x1+2)*(y0+y1+2))
    # return 4*((xy00+p00)*(xy11+p11) - (xy01+p01)*(xy10+p10))/((xy00+xy01+xy10+xy11+4)*(xy00+xy01+xy10+xy11+5))

# approximates the variance graph using Bayesian estimates
def bayes_variance_graph(X,cc):
    # Inputs:
    #     X  - (numpy.array{dict}) - array for tracking measurement outcomes
    #     cc - (list{float})       - coefficients of Hamiltonian
    # Outputs:
    #     (numpy.array{float}) - variance graph calculated with Bayesian estimates
    p = len(cc)
    cc_conj = [np.conj(c) for c in cc]
    return graph(np.array([[cc_conj[i0]*cc[i0]*bayes_Var(X[i0,i0]) if i0==i1 else cc_conj[i0]*cc[i1]*bayes_Cov(X[i0,i1],X[i0,i0],X[i1,i1]) for i1 in range(p)] for i0 in range(p)]))

# naive estimation of mean from samples
def naive_Mean(xDict):
    # Inputs:
    #     xDict - (Dict) - number of ++/+-/-+/-- outcomes for single Pauli
    # Outputs:
    #     (float) - Bayesian estimate of mean
    x0,x1 = xDict[(1,1)],xDict[(-1,-1)]
    if (x0+x1) == 0:
        return 0
    return (x0-x1)/(x0+x1)

# naive estimation of variance from samples
def naive_Var(xDict):
    # Inputs:
    #     xDict - (Dict) - number of ++/+-/-+/-- outcomes for single Pauli
    # Outputs:
    #     (float) - Bayesian variance of mean
    x0,x1 = xDict[(1,1)],xDict[(-1,-1)]
    if (x0+x1) == 0:
        return 2/3
    return 4*(x0*x1)/((x0+x1)*(x0+x1))

def naive_Cov(xyDict,xDict,yDict):
    # naive estimation of covariance from samples
    # Inputs:
    #     xyDict - (Dict) - number of ++/+-/-+/-- outcomes for pair of Paulis
    #     xDict  - (Dict) - number of ++/+-/-+/-- outcomes for first Pauli
    #     xDict  - (Dict) - number of ++/+-/-+/-- outcomes for second Pauli
    # Outputs:
    #     (float) - naive estimate of mean
    xy00, xy01, xy10, xy11 = xyDict[(1, 1)], xyDict[(1, -1)], xyDict[(-1, 1)], xyDict[(-1, -1)]
    x0, x1 = xDict[(1, 1)], xDict[(-1, -1)]
    y0, y1 = yDict[(1, 1)], yDict[(-1, -1)]
    if (xy00 + xy01 + xy10 + xy11) == 0:
        return 0
    return 4 * ((xy00) * (xy11) - (xy01) * (xy10)) / ((xy00 + xy01 + xy10 + xy11) * (xy00 + xy01 + xy10 + xy11))

def naive_variance_graph(X,cc):
    # approximates the variance graph using naive estimates
    # Inputs:
    #     X  - (numpy.array{dict}) - array for tracking measurement outcomes
    #     cc - (list{float})       - coefficients of Hamiltonian
    # Outputs:
    #     (numpy.array{float}) - variance graph calculated with naive estimates
    p = len(cc)
    return graph(np.array([[(cc[i0]**2)*naive_Var(X[i0,i0]) if i0==i1 else cc[i0]*cc[i1]*naive_Cov(X[i0,i1],X[i0,i0],X[i1,i1]) for i1 in range(p)] for i0 in range(p)]))



# SIMULATION ALGORITHMS

# convert from L,l notation to set of update steps
def Ll_updates(L,l,shots):
    # Inputs:
    #     L     - (int) - number of sections into which shots should be split
    #     l     - (int) - exponential scaling factor for size of sections
    #     shots - (int) - total number of shots required
    # Outputs:
    #     (set{int}) - set containing steps at which algorithm should update
    r0_shots = shots/sum([(1+l)**i for i in range(L)])
    shot_nums = [round(r0_shots*(1+l)**i) for i in range(L-1)]
    shot_nums.append(shots-sum(shot_nums))
    return set([0]+list(itertools.accumulate(shot_nums))[:-1])

# updates the variance matrix by sampling from pre-determined cliques
def variance_estimate_(P,cc,psi,D,X,xxx):
    # Inputs:
    #     P   - (pauli)             - Paulis in Hamiltonian
    #     cc  - (list{int})         - coefficients in Hamiltonian
    #     psi - (numpy.array)       - ground state of Hamiltonian
    #     D   - (dict)              - dictionary for storing pdf and negations for future samples
    #     X   - (numpy.array{dict}) - array of measurement outcome counts
    #     xxx - (list{list{int}})   - list of cliques to-be-sampled
    # Outputs:
    #     (numpy.array{float}) - variance graph calculated with Bayesian estimates
    #     (dict)               - (updated) dictionary for storing pdf and negations for future samples
    #     (numpy.array{dict})  - (updated) array of measurement outcome counts
    p = P.paulis()
    index_set = set(range(p))
    for aa in xxx:
        aa1 = sorted(index_set.difference(aa))
        cc1 = sample_(P,psi,aa,D)
        for (a0,c0),(a1,c1) in itertools.product(zip(aa,cc1),repeat=2):
            X[a0,a1][(c0,c1)] += 1
    return bayes_variance_graph(X,cc).adj,D,X

# partitions Hamiltonian and repeatedly samples cliques while minimizing total variance
#     returns an array of dictionaries which tracks ++/+-/-+/-- outcomes for each pair of Paulis
def bucket_filling(P,cc,psi,shots,part_func,update_steps=set([]),repeats=(0,1),full_simulation=False,general_commutation=True):
    # Inputs:
    #     P                   - (pauli)       - Paulis in Hamiltonian
    #     cc                  - (list{int})   - coefficients in Hamiltonian
    #     psi                 - (numpy.array) - ground state of Hamiltonian
    #     shots               - (int)         - number of samples to take
    #     part_func           - (function)    - function for determining partition
    #     update_steps        - (set{int})    - steps at which variance graph should be updated
    #     repeats             - (tuple{int})  - current iteration and total number of iterations
    #     full_simulation     - (bool)        - set True if full simulation is required
    #     general_commutation - (bool)        - set True if general commutation is allowed
    # Outputs:
    #     (numpy.array{int})  - array containing number of times each pair of Paulis was measured together
    #     (numpy.array{dict}) - array of measurement outcome counts
    #     (list{list{int}})   - list of cliques which were sampled
    p = P.paulis()
    X = np.array([[dict(zip([(i0,i1) for i0,i1 in itertools.product(range(P.lcm),repeat=2)],[0]*(P.lcm**2))) for a1 in range(p)] for a0 in range(p)])
    if general_commutation:
        CG = commutation_graph(P)
    else:
        CG = quditwise_commutation_graph(P)
    if part_func == weighted_vertex_covering_maximal_cliques:
        aaa = part_func(CG,cc=cc,k=3)
    else:
        aaa = part_func(CG)
    D = {}
    S = np.zeros((p,p),dtype=int)
    Ones = [np.ones((i,i),dtype=int) for i in range(p+1)]
    index_set = set(range(p))
    xxx = []
    xxx1 = []
    S[range(p),range(p)] += np.array([1 for i in range(p)])
    for i0 in range(shots):
        if i0 == 0 or i0 in update_steps:
            V,D,X = variance_estimate_(P,cc,psi,D,X,xxx1)
            xxx1 = []
        S1 = S+Ones[p]
        s = 1/(S.diagonal()|(S.diagonal()==0))
        s1 = 1/S1.diagonal()
        factor = p-np.count_nonzero(S.diagonal())
        S1[range(p),range(p)] = [a if a != 1 else -factor for a in S1.diagonal()]
        V1 = V*(S*s*s[:,None] - S1*s1*s1[:,None])
        V2 = 2*V*(S*s*s[:,None] - S*s*s1[:,None])
        aaa,aaa1 = itertools.tee(aaa,2)
        # aa = sorted(max(aaa1,key=lambda xx : np.abs(V1[xx][:,xx].sum()+V2[xx][:,list(index_set.difference(xx))].sum())))
        aa = sorted(random.sample(list(set([frozenset(aa1) for aa1 in aaa1])),1)[0])
        xxx.append(aa)
        xxx1.append(aa)
        S[np.ix_(aa,aa)] += Ones[len(aa)]
        loading_bar([(i0,shots),repeats],scalings=[lambda x:x**(3/2)])
    S[range(p),range(p)] -= np.array([1 for i in range(p)])
    if full_simulation:
        for aa in xxx1:
            aa1 = sorted(index_set.difference(aa))
            cc1 = sample_(P,psi,aa,D)
            for (a0,c0),(a1,c1) in itertools.product(zip(aa,cc1),repeat=2):
                X[a0,a1][(c0,c1)] += 1
    else:
        X = None
    return S,X,xxx

def bucket_filling_mod(P,cc,psi,shots,part_func,update_steps=set([]),repeats=(0,1),
                       full_simulation=False,general_commutation=True,best_possible = False):
    # Inputs:
    #     P                   - (pauli)       - Paulis in Hamiltonian
    #     cc                  - (list{int})   - coefficients in Hamiltonian
    #     psi                 - (numpy.array) - ground state of Hamiltonian
    #     shots               - (int)         - number of samples to take
    #     part_func           - (function)    - function for determining partition
    #     update_steps        - (set{int})    - steps at which variance graph should be updated
    #     repeats             - (tuple{int})  - current iteration and total number of iterations
    #     full_simulation     - (bool)        - set True if full simulation is required
    #     general_commutation - (bool)        - set True if general commutation is allowed
    # Outputs:
    #     (numpy.array{int})  - array containing number of times each pair of Paulis was measured together
    #     (numpy.array{dict}) - array of measurement outcome counts
    #     (list{list{int}})   - list of cliques which were sampled
    if best_possible:
        vg = variance_graph(P, cc, psi)
    
    p = P.paulis()
    X = np.array([[dict(zip([(i0,i1) for i0,i1 in itertools.product(range(P.lcm),repeat=2)],[0]*(P.lcm**2))) for a1 in range(p)] for a0 in range(p)])
    if general_commutation:
        CG = commutation_graph(P)
    else:
        CG = quditwise_commutation_graph(P)
    if part_func == weighted_vertex_covering_maximal_cliques:
        aaa = part_func(CG,cc=cc,k=3)
    else:
        aaa = part_func(CG)
    D = {}
    S = np.zeros((p,p),dtype=int)
    Ones = [np.ones((i,i),dtype=int) for i in range(p+1)]
    index_set = set(range(p))
    xxx = []
    xxx1 = []
    S[range(p),range(p)] += np.array([1 for i in range(p)])
    for i0 in range(shots):
        if i0 == 0 or i0 in update_steps:
            V,D,X = variance_estimate_(P,cc,psi,D,X,xxx1)
            if best_possible == True:
                V = vg.adj
            xxx1 = []
        S1 = S+Ones[p]
        s = 1/(S.diagonal()|(S.diagonal()==0))
        s1 = 1/S1.diagonal()
        factor = p-np.count_nonzero(S.diagonal())
        S1[range(p),range(p)] = [a if a != 1 else -factor for a in S1.diagonal()]
        V1 = V*(S*s*s[:,None] - S1*s1*s1[:,None])
        V2 = 2*V*(S*s*s[:,None] - S*s*s1[:,None])
        aaa,aaa1 = itertools.tee(aaa,2)
        aa = sorted(max(aaa1,key=lambda xx : np.abs(V1[xx][:,xx].sum()+V2[xx][:,list(index_set.difference(xx))].sum())))
        #aa = sorted(random.sample(list(set([frozenset(aa1) for aa1 in aaa1])),1)[0])
        xxx.append(aa)
        xxx1.append(aa)
        S[np.ix_(aa,aa)] += Ones[len(aa)]
        loading_bar([(i0,shots),repeats],scalings=[lambda x:x**(3/2)])
    S[range(p),range(p)] -= np.array([1 for i in range(p)])
    if full_simulation:
        for aa in xxx1:
            aa1 = sorted(index_set.difference(aa))
            cc1 = sample_(P,psi,aa,D)
            for (a0,c0),(a1,c1) in itertools.product(zip(aa,cc1),repeat=2):
                X[a0,a1][(c0,c1)] += 1
    else:
        X = None
    return S,X,xxx



# provides a dictionary which contains the circuits, Paulis, eigenvalues, et al. for every group in the partition
def equal_allocation_algorithm(P,cc,general_commutation=True):
    # Inputs:
    #     P                   - (pauli)     - Paulis in Hamiltonian
    #     cc                  - (list{int}) - coefficients in Hamiltonian
    #     general_commutation - (bool)      - set True if general commutation is allowed
    # Outputs:
    #     (dict) - a dictionary indexed by the indices of the sets of Paulis (converetd to strings) containing:
    #              (circuit)                - circuit which diagonalizes these Paulis
    #              (list{pauli})            - list of Paulis within the partition
    #              (list{pauli})            - list of Paulis within the partition after applying diagonalization circuit
    #              (list{np.complex})       - list of coefficients corresponding to these Paulis
    #              (list{tuple{list,list}}) - list of tuples of measurement outcomes and eigenvalues
    #                                         each measurement outcome is paired with a list of the corresponding eigenvalues of each Pauli
    #                                         the eigenvalues are stored as integers modulo the least common multiple of the dimensions
    if general_commutation:
        aaa = LDF(commutation_graph(P))
    else:
        aaa = LDF(quditwise_commutation_graph(P))
    measurement_dictionary = dict([])
    for aa in aaa:
        aa = sorted(aa)
        P1 = P.copy()
        P1.delete_paulis_([i for i in range(P.paulis()) if not i in aa])
        C = diagonalize(P1)
        P1 = act(P1,C)
        pauli_list = [P.a_pauli(a) for a in aa]
        diagonalized_pauli_list = [P1.a_pauli(i) for i in range(len(aa))]
        coefficient_list = [cc[a] for a in aa]
        eigenvalues_list = []
        for a1 in range(np.prod(P.dims)):
            eigenvalues_list.append([(P1.phases[i0]+sum((int_to_bases(a1,P1.dims)[i1]*P1.Z[i0,i1]*P1.lcm)//P1.dims[i1] for i1 in range(P1.qudits())))%P1.lcm for i0 in range(P1.paulis())])
        measurement_dictionary[str(aa)] = (C,pauli_list,diagonalized_pauli_list,coefficient_list,eigenvalues_list)
    return measurement_dictionary

# determines the number of measurements required to reach desired error (as a proportion of the true mean)
#     note that this algorithm calculates the true ground state, mean, and variance
#     so it should be used to observe trends on small examples, but isn't realistic for large examples
def equal_allocation_measurements(P,cc,error,general_commutation=True):
    # Inputs:
    #     P                   - (pauli)     - Paulis in Hamiltonian
    #     cc                  - (list{int}) - coefficients in Hamiltonian
    #     error               - (float)     - desired error as a proportion of the true mean
    #     general_commutation - (bool)      - set True if general commutation is allowed
    # Outputs:
    #     (int) - number of measurements each clique must be measured to reach this error
    p = P.paulis()
    psi = ground_state(P,cc)
    true_Mean = Hamiltonian_Mean(P,cc,psi).real
    true_Variance_graph = variance_graph(P,cc,psi)
    if general_commutation:
        aaa = LDF(commutation_graph(P))
    else:
        aaa = LDF(quditwise_commutation_graph(P))
    S = np.zeros((p,p),dtype=int)
    Ones = [np.ones((i,i),dtype=int) for i in range(p+1)]
    for aa in aaa:
        S[np.ix_(aa,aa)] += Ones[len(aa)]
    one_shot_error = np.sqrt(np.sum(scale_variances(true_Variance_graph,S).adj).real)
    return math.ceil((one_shot_error/(error*true_Mean))**2)


#EXTRA STUFF:
#Function to reconstruct expectation values (and errors)
def expt_rec(beta_exp , Ptot , Pe , Pm , cce , ccm , elmag , Michael_state = True ,
             shots = 1000, part_func = LDF , no_simulation = False , full_simulation = True , update_steps = set([10000,100000]) , printing = False , general_commutation = False):
    
    #beta value and coefficients of total Hamiltonian:
    beta = 10**beta_exp
    cct = ([beta * el for el in ccm]) + ([beta**-1 * el for el in cce])
        
    #parameters required below:
    pt,qt = Ptot.paulis(),Ptot.qudits()
    pe,qe = Pe.paulis(),Pe.qudits()
    pm,qm = Pm.paulis(),Pm.qudits()
    
    #import corresponding ground state
    if Michael_state:
        if elmag == "E":
            psi = np.load("./Expt_data/dms/E_basis/state_"+str(beta_exp)+".npy")
        elif elmag == "B":
            psi = np.load("./Expt_data/dms/B_basis/state_"+str(beta_exp)+".npy")
        if np.max(abs(np.array(psi@psi)-np.array(psi)))<10**-10:
            index_chosen = np.diag(psi).argmax()
            new_psi = psi[index_chosen]
            psi = new_psi/np.linalg.norm(new_psi)
        else:
            print("STATE IS NOT PURE!!!!")
    else:
        psi = ground_state(Ptot,cct)
    
    #if printing, print expected values:
    if printing:
        print("chosen beta: ",beta)
        print("total energy: ",Hamiltonian_Mean(Ptot,cct,psi).real)
        print("electric dimensionless energy: ",Hamiltonian_Mean(Pe,cce,psi).real)
        print("plaquette: ",-Hamiltonian_Mean(Pm,ccm,psi).real/4)
        print()
        print()
    
    #determine experimental results:
    
    if not no_simulation:
        St,Xt,xxxt = bucket_filling(Ptot,cct,psi,shots,part_func,full_simulation=full_simulation,update_steps=update_steps,general_commutation=general_commutation)
        if printing:
            print("first round done :)")
        Se,Xe,xxxe = bucket_filling(Pe,cce,psi,shots,part_func,full_simulation=full_simulation,update_steps=update_steps,general_commutation=general_commutation)
        if printing:
            print("second round done :)")
        Sm,Xm,xxxm = bucket_filling(Pm,ccm,psi,shots,part_func,full_simulation=full_simulation,update_steps=update_steps,general_commutation=general_commutation)
        if printing:
            print("third round done - almost there! :)")
            print()
            print()

        #Getting the actual values:

        #total energy:
        tot_en_true = Hamiltonian_Mean(Ptot,cct,psi).real
        if printing:
            print('TRUE TOTAL ENERGY')
            print('True mean:',tot_en_true)
        if not Xt is None:
            tot_en_est = sum(cct[i0]*sum(Xt[i0,i0][i1,i1]*math.e**(2*1j*math.pi*i1/Ptot.lcm) for i1 in range(Ptot.lcm))/sum(Xt[i0,i0][i1,i1] for i1 in range(Ptot.lcm)) if sum(Xt[i0,i0][i1,i1] for i1 in range(Ptot.lcm))>0 else 0 for i0 in range(pt)).real
            if printing:
                print('Est. mean:',tot_en_est)
        tot_en_error_true = np.sqrt(np.sum(scale_variances(variance_graph(Ptot,cct,psi),St).adj).real)
        if printing:
            print('True error:',tot_en_error_true)
        if not Xt is None:
            tot_en_error_est = np.sqrt(np.sum(scale_variances(bayes_variance_graph(Xt,cct),St).adj)).real
            if printing:
                print('Est. error:',tot_en_error_est)
        if printing:
            print()
            print()

        #electric contribution:
        elec_true = Hamiltonian_Mean(Pe,cce,psi).real
        if printing:
            print('TRUE ELECTRIC (dimless) ENERGY')
            print('True mean:',elec_true)
        if not Xe is None:
            elec_est = sum(cce[i0]*sum(Xe[i0,i0][i1,i1]*math.e**(2*1j*math.pi*i1/Pe.lcm) for i1 in range(Pe.lcm))/sum(Xe[i0,i0][i1,i1] for i1 in range(Pe.lcm)) if sum(Xe[i0,i0][i1,i1] for i1 in range(Pe.lcm))>0 else 0 for i0 in range(pe)).real
            if printing:
                print('Est. mean:',elec_est)
        elec_error_true = np.sqrt(np.sum(scale_variances(variance_graph(Pe,cce,psi),Se).adj).real)
        if printing:
            print('True error:',elec_error_true)
        if not Xe is None:
            elec_error_est = np.sqrt(np.sum(scale_variances(bayes_variance_graph(Xe,cce),Se).adj)).real
            if printing:
                print('Est. error:',elec_error_est)
        if printing:
            print()
            print()

        #magnetic (plaquette) contribution 
        plaq_true = -Hamiltonian_Mean(Pm,ccm,psi).real/4
        if printing:
            print('TRUE PLAQUETTE')
            print('True mean:',plaq_true)
        if not Xm is None:
            plaq_est = -sum(ccm[i0]*sum(Xm[i0,i0][i1,i1]*math.e**(2*1j*math.pi*i1/Pm.lcm) for i1 in range(Pm.lcm))/sum(Xm[i0,i0][i1,i1] for i1 in range(Pm.lcm)) if sum(Xm[i0,i0][i1,i1] for i1 in range(Pm.lcm))>0 else 0 for i0 in range(pm)).real/4
            if printing:
                print('Est. mean:',plaq_est)
        plaq_error_true = np.sqrt(np.sum(scale_variances(variance_graph(Pm, ccm, psi), Sm).adj).real) / 4
        if printing:
            print('True error:', plaq_error_true)
        if not Xm is None:
            plaq_error_est = np.sqrt(np.sum(scale_variances(bayes_variance_graph(Xm, ccm), Sm).adj)).real / 4
            if printing:
                print('Est. error:', plaq_error_est)
        if printing:
            print()
            print()

        #return
        if not Xt is None:
            return ([tot_en_true , tot_en_est , tot_en_error_true , tot_en_error_est], 
                    [elec_true , elec_est , elec_error_true , elec_error_est], 
                    [plaq_true , plaq_est , plaq_error_true , plaq_error_est])
        else:
            return ([tot_en_true , tot_en_error_true], 
                    [elec_true , elec_error_true], 
                    [plaq_true , plaq_error_true])
    else:
        return ([Hamiltonian_Mean(Ptot,cct,psi).real , "None" , "None" , "None"], 
                [Hamiltonian_Mean(Pe,cce,psi).real , "None" , "None" , "None"], 
                [-Hamiltonian_Mean(Pm,ccm,psi).real/4 , "None" , "None" , "None"])










